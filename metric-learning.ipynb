{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.Resize(224),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_filter_dataset(dataset):\n",
    "    images, labels = [], []\n",
    "    cat_counter = 0\n",
    "    for train in dataset:\n",
    "        X, y = train[0], train[1]\n",
    "        if y == 5: # dog\n",
    "            images.append(X)\n",
    "            labels.append(y)\n",
    "        elif y == 3: # cat\n",
    "            if cat_counter == 500:\n",
    "                continue\n",
    "            images.append(X)\n",
    "            labels.append(y)\n",
    "            cat_counter += 1\n",
    "    return torch.stack(images), torch.Tensor(labels)\n",
    "\n",
    "\n",
    "images, labels = load_filter_dataset(trainset)\n",
    "test_images, test_labels = load_filter_dataset(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NPairSamplerCifar(Dataset):\n",
    "    def __init__(self, images, labels, n):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.n = n\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    " \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.images[idx]\n",
    "        t = self.labels[idx]\n",
    "        xp_idx = np.random.choice(np.where(self.labels == t)[0])\n",
    "        xp = self.images[xp_idx]\n",
    "        xn = []\n",
    "        for i in range(self.n):\n",
    "            xn_idx = np.random.choice(np.where(self.labels != t)[0])\n",
    "            xn_tmp = self.images[xn_idx]\n",
    "            xn.append(xn_tmp)\n",
    "        return x, t, xp, torch.stack(xn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = NPairSamplerCifar(images, labels, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 224, 224])\n",
      "torch.Size([])\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([5, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "for i in sampler[0]:\n",
    "    print(i.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CifarDataset(Dataset):\n",
    "    def __init__(self, images, labels):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    " \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.images[idx]\n",
    "        t = self.labels[idx]\n",
    "        xp_idx = np.random.choice(np.where(self.labels == t)[0])\n",
    "        xn_idx = np.random.choice(np.where(self.labels != t)[0])\n",
    "        xp = self.images[xp_idx]\n",
    "        xn = self.images[xn_idx]\n",
    "        return x, t, xp, xn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CifarDataset(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletResNet(nn.Module):\n",
    "    def __init__(self, out_dim, n_classes):\n",
    "        super(TripletResNet, self).__init__()\n",
    "        resnet = torchvision.models.__dict__['resnet18'](pretrained=True)\n",
    "        for params in resnet.parameters():\n",
    "            params.requires_grad = False\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            resnet.conv1,\n",
    "            resnet.bn1,\n",
    "            resnet.relu,\n",
    "            resnet.maxpool,\n",
    "            resnet.layer1,\n",
    "            resnet.layer2,\n",
    "            resnet.layer3,\n",
    "            resnet.layer4,\n",
    "            resnet.avgpool,\n",
    "        )\n",
    "        self.fc1 = nn.Linear(resnet.fc.in_features, out_dim)\n",
    "        self.fc2 = nn.Linear(out_dim, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        metric = F.normalize(self.fc1(x))\n",
    "        classes = self.fc2(metric)\n",
    "        return metric, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletLoss(nn.Module):\n",
    "    def __init__(self, margin=0.2):\n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, anchor, t, positive, negative):\n",
    "        dist = torch.sum(\n",
    "            torch.pow((anchor - positive), 2) - torch.pow((anchor - negative), 2),\n",
    "            dim=1) + self.margin\n",
    "        dist = F.relu(dist)\n",
    "        loss = torch.mean(dist)\n",
    "        y_0 = anchor[t==0]\n",
    "        if len(y_0) > 0:\n",
    "            loss += torch.mean(y_0**2)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flow_data(model, data_loader, optimizer=None):\n",
    "    if optimizer is None:\n",
    "        model.eval()\n",
    "        training = False\n",
    "    else:\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        training = True\n",
    "\n",
    "    epoch_loss = 0\n",
    "    for i, (anchors, labels, positives, negatives) in enumerate(data_loader):\n",
    "        anchors = anchors.to(device)\n",
    "        labels = labels.to(device)\n",
    "        positives = positives.to(device)\n",
    "        negatives = negatives.to(device)\n",
    "\n",
    "        out_anc, _ = model(anchors)\n",
    "        out_pos, _ = model(positives)\n",
    "        out_neg, _ = model(negatives)\n",
    "\n",
    "        loss = criterion(out_anc, labels, out_pos, out_neg)\n",
    "\n",
    "        if training:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        epoch_loss += loss.item()\n",
    "    return epoch_loss / len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-3bfd560b0947>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mtrain_epoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mvalid_epoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflow_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mvalid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflow_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-7669d9b9a900>\u001b[0m in \u001b[0;36mflow_data\u001b[0;34m(model, data_loader, optimizer)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mout_neg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnegatives\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_anc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_neg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-a5532b988524>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, anchor, t, positive, negative)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0my_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manchor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_0\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, random_state=27, shuffle=True)\n",
    "\n",
    "for cv_i, (train_idx, valid_idx) in enumerate(cv.split(images, labels)):\n",
    "    train_dataset = CifarDataset(images[train_idx], labels[train_idx])\n",
    "    valid_dataset = CifarDataset(images[valid_idx], labels[valid_idx])\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=32)\n",
    "\n",
    "    model = TripletResNet(100, 2)\n",
    "    model = model.to(device)\n",
    "    criterion = TripletLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), \n",
    "                                lr=0.001, momentum=0.9, weight_decay=1e-4)\n",
    "\n",
    "    for epoch in range(2):\n",
    "        train_epoch_loss = 0\n",
    "        valid_epoch_loss = 0\n",
    "        train_loss = flow_data(model, train_loader, optimizer=optimizer)\n",
    "        valid_loss = flow_data(model, valid_loader)\n",
    "\n",
    "        train_epoch_loss += train_loss.item()\n",
    "        valid_epoch_loss += valid_loss.item()\n",
    "\n",
    "        print('EPOCH: [{epoch}/{2}], train_loss: {train_epoch_loss:.3f}, valid_loss: {valid_epochs_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletSamplerCifar(Dataset):\n",
    "    def __init__(self, images, labels):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    " \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.images[idx]\n",
    "        t = self.labels[idx]\n",
    "        xp_idx = np.random.choice(np.where(self.labels == t)[0])\n",
    "        xn_idx = np.random.choice(np.where(self.labels != t)[0])\n",
    "        xp = self.images[xp_idx]\n",
    "        xn = self.images[xn_idx]\n",
    "        return x, t, xp, xn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
